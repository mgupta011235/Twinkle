{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "import pymongo\n",
    "import nltk.data\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from scipy.spatial.distance import cdist\n",
    "from nltk import pos_tag\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from pymongo import MongoClient\n",
    "from random import sample\n",
    "import statsmodels.api as sm\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "\n",
    "# for timing\n",
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "import time\n",
    "\n",
    "from random import shuffle\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client['tweets_db']\n",
    "cursor = db.tweets.find()\n",
    "count = 200000\n",
    "tweets = []\n",
    "for tweet in cursor:\n",
    "    count -= 1\n",
    "    try:\n",
    "        if 'text' in tweet:\n",
    "            \n",
    "            td = {}\n",
    "#             td['id'] = tweet['id']\n",
    "            td['text'] = tweet['text']\n",
    "            td['hashtags'] = tweet['entities']['hashtags'][0]['text']\n",
    "            td['timestamp'] = tweet['created_at']\n",
    "            tweets.append(td)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "    if count <= 0:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(tweets).ix[21,'hashtags'][0]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TVFightsLive</td>\n",
       "      <td>Gotta go with @maudegarrett on this! We only h...</td>\n",
       "      <td>Tue Apr 19 23:57:59 +0000 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDUBLoveOnCue</td>\n",
       "      <td>RT @GasgasAbelgass: THIS GIRL IS FULL OF EXCIT...</td>\n",
       "      <td>Wed Apr 20 00:03:34 +0000 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RelationshipGoals</td>\n",
       "      <td>RT @Cheyennelt: @Tscarmardo1 when she just sup...</td>\n",
       "      <td>Wed Apr 20 00:03:34 +0000 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Opines</td>\n",
       "      <td>IMT and SITRI Partner to Accelerate Developmen...</td>\n",
       "      <td>Wed Apr 20 00:03:34 +0000 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bernie2016</td>\n",
       "      <td>RT @howserob: CBS early exit poll: #Bernie2016...</td>\n",
       "      <td>Wed Apr 20 00:03:35 +0000 2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hashtags                                               text  \\\n",
       "0       TVFightsLive  Gotta go with @maudegarrett on this! We only h...   \n",
       "1     ALDUBLoveOnCue  RT @GasgasAbelgass: THIS GIRL IS FULL OF EXCIT...   \n",
       "2  RelationshipGoals  RT @Cheyennelt: @Tscarmardo1 when she just sup...   \n",
       "3             Opines  IMT and SITRI Partner to Accelerate Developmen...   \n",
       "4         Bernie2016  RT @howserob: CBS early exit poll: #Bernie2016...   \n",
       "\n",
       "                        timestamp  \n",
       "0  Tue Apr 19 23:57:59 +0000 2016  \n",
       "1  Wed Apr 20 00:03:34 +0000 2016  \n",
       "2  Wed Apr 20 00:03:34 +0000 2016  \n",
       "3  Wed Apr 20 00:03:34 +0000 2016  \n",
       "4  Wed Apr 20 00:03:35 +0000 2016  "
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tweets)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a set of documents.\n",
    "tweet_list = []\n",
    "for text in df['text'].values:\n",
    "    text = re.sub(r\"#|@|http\\S+\", \"\", text).lower()\n",
    "    tweet_list.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = [word_tokenize(content) for content in tweet_list]\n",
    "stop = set(stopwords.words('english'))\n",
    "docs = [[word for word in words if word not in stop] for words in docs]\n",
    "# snowball = SnowballStemmer('english')\n",
    "# docs_snowball = [[snowball.stem(word) for word in words] for words in docs]\n",
    "wordnet = WordNetLemmatizer()\n",
    "docs_wordnet = [[wordnet.lemmatize(word) for word in words] for words in docs]\n",
    "docs = docs_wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part of speech tagging\n",
    "# pos_tagged = [pos_tag(tokens) for tokens in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs_joined = [' '.join(x) for x in docs]\n",
    "vectorizer = TfidfVectorizer(use_idf=False)\n",
    "vectorized = vectorizer.fit_transform(docs_joined)\n",
    "words = vectorizer.get_feature_names()\n",
    "docs_vectorized = vectorizer.fit_transform(docs_joined).toarray()\n",
    "cosine_similarities = linear_kernel(vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0 27247  5968 ..., 24996 24995 18992]\n",
      "gotta go with maudegarrett on this! we only have a few seasons left!i want a crazy epic character team up! \n",
      "\n",
      "tvfightslive screenjunkies\n",
      "rt iheartradio: you don't gotta go to work, but you gotta put in work vaguejobdescriptions fifthharmony \n",
      "gorl...... they're both annoying, they gotta go bgc\n"
     ]
    }
   ],
   "source": [
    "print np.argsort(cosine_similarities[0,:])[::-1]\n",
    "print tweet_list[0]\n",
    "print tweet_list[27247]\n",
    "print tweet_list[5968]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0  5968 11237 ...,  8630  8639 24983]]\n",
      "gotta go with maudegarrett on this! we only have a few seasons left!i want a crazy epic character team up! \n",
      "\n",
      "tvfightslive screenjunkies\n",
      "gorl...... they're both annoying, they gotta go bgc\n",
      "rt fabulousfairy: it's a battle in my house, but i've gotta go with voicesaveowen\n"
     ]
    }
   ],
   "source": [
    "print np.argsort(cdist(docs_vectorized[0, :][np.newaxis, :], docs_vectorized, 'cosine'))\n",
    "print tweet_list[0]\n",
    "print tweet_list[5968]\n",
    "print tweet_list[11237]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0  8510 10764 ...,  8346  8369 24983]]\n",
      "gotta go with maudegarrett on this! we only have a few seasons left!i want a crazy epic character team up! \n",
      "\n",
      "tvfightslive screenjunkies\n",
      "rt brookecarbo: as much as love emily, and i do, gotta go voicesaveowen on this one... just adore that voice thevoice\n",
      "rt brookecarbo: as much as love emily, and i do, gotta go voicesaveowen on this one... just adore that voice thevoice\n",
      "rt brookecarbo: as much as love emily, and i do, gotta go voicesaveowen on this one... just adore that voice thevoice\n",
      "rt eloramaxwell: gotta go with emily she takes me to another time and her voice is hauntingly beautiful!! ❤❤voicesaveemily\n",
      "rt brookecarbo: as much as love emily, and i do, gotta go voicesaveowen on this one... just adore that voice thevoice\n"
     ]
    }
   ],
   "source": [
    "print np.argsort(cdist(docs_vectorized[0, :][np.newaxis, :], docs_vectorized, 'jaccard'))\n",
    "print tweet_list[0]\n",
    "print tweet_list[8510]\n",
    "print tweet_list[10764]\n",
    "print tweet_list[8114]\n",
    "print tweet_list[9323]\n",
    "print tweet_list[9838]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 23816 12694 ...,  1035  1037   295]]\n",
      "gotta go with maudegarrett on this! we only have a few seasons left!i want a crazy epic character team up! \n",
      "\n",
      "tvfightslive screenjunkies\n",
      "cuandolluevemedanganasde c o  m e r.\n",
      "its on!!!! containment\n"
     ]
    }
   ],
   "source": [
    "print np.argsort(cdist(docs_vectorized[0, :][np.newaxis, :], docs_vectorized, 'hamming'))\n",
    "print tweet_list[0]\n",
    "print tweet_list[23816]\n",
    "print tweet_list[12694]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0  5968  8246 ...,  4671 15366  6605]]\n",
      "gotta go with maudegarrett on this! we only have a few seasons left!i want a crazy epic character team up! \n",
      "\n",
      "tvfightslive screenjunkies\n",
      "gorl...... they're both annoying, they gotta go bgc\n",
      "rt ktnieb: gotta go with owen because adamlevine asked me to voicesaveowen\n"
     ]
    }
   ],
   "source": [
    "print np.argsort(cdist(docs_vectorized[0, :][np.newaxis, :], docs_vectorized, 'euclidean'))\n",
    "print tweet_list[0]\n",
    "print tweet_list[5968]\n",
    "print tweet_list[8246]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0  7879  7881 ..., 20606   436 13843]]\n",
      "gotta go with maudegarrett on this! we only have a few seasons left!i want a crazy epic character team up! \n",
      "\n",
      "tvfightslive screenjunkies\n",
      "rt to voicesaveowen \n",
      "rt to voicesaveowen \n"
     ]
    }
   ],
   "source": [
    "print np.argsort(cdist(docs_vectorized[0, :][np.newaxis, :], docs_vectorized, 'seuclidean', V=None))\n",
    "print tweet_list[0]\n",
    "print tweet_list[7879]\n",
    "print tweet_list[7881]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0  5968 17081 ..., 20501 20556  9450]]\n",
      "gotta go with maudegarrett on this! we only have a few seasons left!i want a crazy epic character team up! \n",
      "\n",
      "tvfightslive screenjunkies\n",
      "gorl...... they're both annoying, they gotta go bgc\n",
      "if you gotta girlfriend saythat\n"
     ]
    }
   ],
   "source": [
    "print np.argsort(cdist(docs_vectorized[0, :][np.newaxis, :], docs_vectorized, 'sqeuclidean'))\n",
    "print tweet_list[0]\n",
    "print tweet_list[5968]\n",
    "print tweet_list[17081]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def most_similar(lst, tweets):\n",
    "    '''\n",
    "    IN: LIST, INTEGER, LIST\n",
    "    OUT: LIST\n",
    "    Return the tweets for indices with the highest n values.\n",
    "    '''\n",
    "    return [tweets[i] for i in np.argsort(lst)[-1:-n-1:-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
